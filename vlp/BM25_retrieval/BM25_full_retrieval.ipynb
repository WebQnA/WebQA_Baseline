{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os, random, json, pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_dir = \"/home/yingshac/CYS/WebQnA/WebQnA_data_new/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute scores for BM25 full-scale retrieval"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "### Load val/test Retrieval_answers\n",
    "split='test'\n",
    "imgRetrievalAns = pickle.load(open(os.path.join(data_dir, \"CLIP_retrieval_experiments/{}_imgRetrievalAns.pkl\".format(split)), \"rb\"))\n",
    "txtRetrievalAns = pickle.load(open(os.path.join(data_dir, \"CLIP_retrieval_experiments/{}_txtRetrievalAns.pkl\".format(split)), \"rb\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "QimgBM25_top2_i = torch.load(\"result_matrix_II.pt\".format(split))\n",
    "QtxtBM25_top2_i = torch.load(\"result_matrix_TT.pt\".format(split))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def compute_retrieval_metrics(pred, gth):\n",
    "\n",
    "    common = len(set(pred).intersection(gth))\n",
    "    RE = common / (len(gth)) \n",
    "    PR = common / (len(pred)) # No protection against division by zero because it's assumed that CLIP never gives empty output\n",
    "    F1 = 2*PR*RE / (PR + RE + 1e-5)\n",
    "    return F1, RE, PR"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "top2_perf = [compute_retrieval_metrics(set(QimgBM25_top2_i[i].numpy()), set(imgRetrievalAns[i])) for i in range(len(imgRetrievalAns))]\n",
    "print(\"BM25 Top2 img queries: F1={:.4f}, RE={:.4f}, PR={:.4f}\".format(np.mean([P[0] for P in top2_perf]), np.mean([P[1] for P in top2_perf]), np.mean([P[2] for P in top2_perf]) ))\n",
    "\n",
    "top2_perf = [compute_retrieval_metrics(set(QtxtBM25_top2_i[i].numpy()), set(txtRetrievalAns[i])) for i in range(len(txtRetrievalAns))]\n",
    "print(\"BN25 Top2 txt queries: F1={:.4f}, RE={:.4f}, PR={:.4f}\".format(np.mean([P[0] for P in top2_perf]), np.mean([P[1] for P in top2_perf]), np.mean([P[2] for P in top2_perf]) ))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BM25 Top2 img queries: F1=0.2019, RE=0.2574, PR=0.1742\n",
      "BN25 Top2 txt queries: F1=0.3342, RE=0.3334, PR=0.3356\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "### Refer to I/T_unknown_modality_bm25.py. \n",
    "### The I_corpus was appended after T_corpus. So all img indices are shifted by 544489\n",
    "imgRetrievalAns_unknownM = {}\n",
    "for i in imgRetrievalAns:\n",
    "    imgRetrievalAns_unknownM[i] = [j+544489 for j in imgRetrievalAns[i]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "QimgBM25_unknownM_top2_i = torch.load(\"result_matrix_Iall.pt\".format(split))\n",
    "QtxtBM25_unknownM_top2_i = torch.load(\"result_matrix_Tall.pt\".format(split))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "top2_perf = [compute_retrieval_metrics(set(QimgBM25_unknownM_top2_i[i].numpy()), set(imgRetrievalAns_unknownM[i])) for i in range(len(imgRetrievalAns_unknownM))]\n",
    "print(\"BM25 Top2 unknownM img queries: F1={:.4f}, RE={:.4f}, PR={:.4f}\".format(np.mean([P[0] for P in top2_perf]), np.mean([P[1] for P in top2_perf]), np.mean([P[2] for P in top2_perf]) ))\n",
    "\n",
    "top2_perf = [compute_retrieval_metrics(set(QtxtBM25_unknownM_top2_i[i].numpy()), set(txtRetrievalAns[i])) for i in range(len(txtRetrievalAns))]\n",
    "print(\"BN25 Top2 unknownM txt queries: F1={:.4f}, RE={:.4f}, PR={:.4f}\".format(np.mean([P[0] for P in top2_perf]), np.mean([P[1] for P in top2_perf]), np.mean([P[2] for P in top2_perf]) ))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BM25 Top2 unknownM img queries: F1=0.2043, RE=0.2597, PR=0.1767\n",
      "BN25 Top2 unknownM txt queries: F1=0.2815, RE=0.2810, PR=0.2825\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BM25 Restricted Retrieval"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dataset = json.load(open(\"/home/yingshac/CYS/WebQnA/WebQnA_data_new/WebQA_0904_concat_newimgid_newguid.json\", \"r\"))\n",
    "print(Counter([dataset[k]['split'] for k in dataset]))\n",
    "print(len(set([dataset[k]['Guid'] for k in dataset])))\n",
    "print(Counter([dataset[k]['Qcate'] for k in dataset]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({'train': 36766, 'test': 7540, 'val': 4966})\n",
      "49272\n",
      "Counter({'text': 24343, 'YesNo': 8255, 'Others': 6470, 'choose': 5201, 'number': 2318, 'color': 2058, 'shape': 627})\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from gensim import corpora\n",
    "from gensim.summarization import bm25"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "retricted_bm25_scores = {'Qimg': [], 'Qtxt': []}\n",
    "for g in tqdm(list(dataset.keys())):\n",
    "    if not dataset[g]['split'] == 'test': continue\n",
    "    key = 'Qtxt' if dataset[g]['Qcate'] == 'text' else 'Qimg'\n",
    "    corpus = []\n",
    "    if key == 'Qtxt':\n",
    "        corpus.extend([x['fact'].split() for x in dataset[g]['txt_posFacts']])\n",
    "        ans = list(range(len(corpus)))\n",
    "    else:\n",
    "        corpus.extend([x['caption'].split() for x in dataset[g]['img_posFacts']])\n",
    "        ans = list(range(len(corpus)))\n",
    "    corpus.extend([x['fact'].split() for x in dataset[g]['txt_negFacts']])\n",
    "    corpus.extend([x['caption'].split() for x in dataset[g]['img_negFacts']])\n",
    "\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    corpus = [dictionary.doc2bow(text) for text in corpus]\n",
    "    bm25_obj = bm25.BM25(corpus)\n",
    "\n",
    "    query_doc = dictionary.doc2bow(dataset[g]['Q'].replace('\"', '').split())\n",
    "    scores = bm25_obj.get_scores(query_doc)\n",
    "    best_docs = sorted(range(len(scores)), key=lambda i: scores[i])[-2:]\n",
    "\n",
    "    retricted_bm25_scores[key].append(compute_retrieval_metrics(set(best_docs), set(ans)))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 49272/49272 [00:16<00:00, 3056.96it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "print(len(retricted_bm25_scores['Qimg']), len(retricted_bm25_scores['Qtxt']))\n",
    "print(\"BM25 Top2 unknownM img queries: F1={:.4f}, RE={:.4f}, PR={:.4f}\".format(np.mean([P[0] for P in retricted_bm25_scores['Qimg']]), np.mean([P[1] for P in retricted_bm25_scores['Qimg']]), np.mean([P[2] for P in retricted_bm25_scores['Qimg']]) ))\n",
    "print(\"BM25 Top2 unknownM txt queries: F1={:.4f}, RE={:.4f}, PR={:.4f}\".format(np.mean([P[0] for P in retricted_bm25_scores['Qtxt']]), np.mean([P[1] for P in retricted_bm25_scores['Qtxt']]), np.mean([P[2] for P in retricted_bm25_scores['Qtxt']]) ))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3464 4076\n",
      "BM25 Top2 unknownM img queries: F1=0.2561, RE=0.3206, PR=0.2239\n",
      "BM25 Top2 unknownM txt queries: F1=0.4375, RE=0.4362, PR=0.4398\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate submission files to eval.ai to double check retrieval results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "### Load uniid2fact\n",
    "fact2uniid = pickle.load(open(os.path.join(data_dir, \"CLIP_retrieval_experiments/fact2uniid.pkl\"), \"rb\"))\n",
    "uniid2fact = {i:fact for fact, i in fact2uniid.items()}\n",
    "\n",
    "# Read test_imgguid2qid, test_txtguid2qid\n",
    "test_imgguid2qid = pickle.load(open(os.path.join(data_dir, \"CLIP_retrieval_experiments/test_imgguid2qid.pkl\"), \"rb\"))\n",
    "test_txtguid2qid = pickle.load(open(os.path.join(data_dir, \"CLIP_retrieval_experiments/test_txtguid2qid.pkl\"), \"rb\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "evalai_submission_BM25_unknownM = {}\n",
    "for g in dataset:\n",
    "    if not dataset[g]['split'] == 'test': continue\n",
    "    if dataset[g]['Qcate'] == 'text':\n",
    "        retrieved_snippet_ids = []\n",
    "        retrieved_facts = []\n",
    "        for x in QtxtBM25_unknownM_top2_i[test_txtguid2qid[g]].tolist():\n",
    "            if x < 544489: retrieved_facts.append(uniid2fact[x])\n",
    "        for x in dataset[g]['txt_posFacts']:\n",
    "            if x['fact'] in retrieved_facts:\n",
    "                retrieved_snippet_ids.append(x['snippet_id'])\n",
    "        retrieved_snippet_ids.extend((2-len(retrieved_snippet_ids))*[\"dummy\"])\n",
    "        evalai_submission_BM25_unknownM[g] = {'sources': retrieved_snippet_ids, 'answer': \"\"}\n",
    "    else:\n",
    "        evalai_submission_BM25_unknownM[g] = \\\n",
    "            {'sources': [ x+30000000-544489 for x in QimgBM25_unknownM_top2_i[test_imgguid2qid[g]].tolist() ], \n",
    "            'answer': \"\"}\n",
    "\n",
    "json.dump(evalai_submission_BM25_unknownM, open(\"evalai_submission_BM25_unknownM.json\", \"w\"))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('py37': conda)"
  },
  "interpreter": {
   "hash": "8b2d563fa8aa45e213139dcbace4d0a578851a3d0a26d4ba28225d6551be83f5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}